\chapter{Common Statistics} 

\section{t-test}
Notes are primary taken from textbook mathematical statistics and data analysis by Rice 3rd edition 
\paragraph{Usage}
Test if two samples $X_1,...,X_n$ and $Y_1,..,Y_m$ has the same mean. Assuming $X$ and $Y$ are iid samples from a normal distribution with the same variance $\sigma^2$ (There is variation method for non-homogeneous variance assumption). If the underlying distributions are not normal but the sample size are large, the use of $t$ distribution can be justified by the CLT. But at the same time, high degree of freedom $t$ distribution is similiar to normal distribution. 

\paragraph{Motivation} Notice the MLE estimate for $\mu_x - \mu_y$ is $\bar{X} - \bar{Y}$. Since $X,Y$ are normally distributed, $\bar{X} - \bar{Y}$ can be expressed as a linear combination of independent normally distributed random variables with the distribution 
    \begin{align*}
        \bar{X} - \bar{Y} \sim N\left[ \mu_x - \mu_y, \sigma^2(\frac{1}{n} + \frac{1}{m} \right]
    \end{align*}
So then if we know the variance $\sigma^2$, we can construct the confidence interval for $\mu_x - \mu_y$ based on standard normal 
    \begin{align*}
        Z = \frac{(\bar{X} - \bar{Y}) - (\mu_x - \mu_y)}{\sigma \sqrt{\frac{1}{n} + \frac{1}{m}}}
    \end{align*}
However, generally $\sigma^2$ is unknown and estimated from the pooled sample variance 
    \begin{align*}
        & s_p^2 = \frac{(n-1)s_x^2 + (m-1)s_y^2}{m+n-2} \\
        & s_x^2 = \frac{1}{(n-1)}\sum_{i=1}^n (x_i - \bar{X})^2
    \end{align*}
    
\paragraph{Definition}
The following statistics follows a $t$ distribution with $m+n-2$ degress of freedom 
    \begin{align*}
        t = \frac{(\bar{X}-\bar{Y}) - (\mu_x - \mu_y)}{s_p \sqrt{\frac{1}{n} + \frac{1}{m}}}
    \end{align*}
So the confidence interval of $100 * (1-\alpha)$ for $\mu_x - \mu_y$ can be constructed as 
    \begin{align*}
        & (\bar{X} - \bar{Y}) \pm t_{m+n-2} (\alpha / 2)s_{\bar{X}- \bar{Y}}\\
        & s_{\bar{X}- \bar{Y}} = s_p \sqrt{\frac{1}{n} + \frac{1}{m}}
    \end{align*}
Alternative hypothesis: 
    \begin{align*}
        & \text{two-sided}: |t| > t_{n+m-2}(\alpha / 2) \\
        & \text{One sided greater}: t > t_{n+m-2}(\alpha)
    \end{align*}
    
    
\section{Power} 

\paragraph{Definition} The power of a test is the probability of rejecting the null hypothesis when it is false. For a two-sample $t$ test, power depends on 
    \begin{itemize}
        \item The real difference $\triangle = \abs{\mu_x - \mu_y}$
        \item $\alpha$
        \item Population standard deviation $\sigma$
        \item Sample size $n$ and $m$
    \end{itemize}
    
    
\paragraph{Example Derivation using Normal Distribution as Approximate t distribution} 
Suppose $\sigma, \alpha, \triangle$ are all given and both samples are size $n$, then 
    \begin{align*}
        Var(\bar{X} - \bar{Y}) = \sigma^2 (\frac{1}{n} + \frac{1}{n}) = \frac{2\sigma^2}{n}
    \end{align*}
The two tailed test at level $\alpha$ is now based on the standard normal 
    \begin{align*}
        Z = \frac{\bar{X} -\bar{Y}}{\sigma \sqrt{2/n}}
    \end{align*}
So the rejection region is $\abs{Z} > z(\alpha/2)$ or 
    \begin{align*}
        \abs{\bar{X} - \bar{Y}} > z(\alpha/2) \sigma \sqrt{2/n}
    \end{align*}
The power of the test is the probability that the test statistics falls in the rejection region under null hypothesis, hence 
    \begin{align*}
        & P\left(\abs{\frac{\bar{X} -\bar{Y}}{\sigma \sqrt{2/n}}} > z(\alpha/2) \right)\\
        & = P\left(  \abs{\bar{X} - \bar{Y}} > z(\alpha/2) \sigma \sqrt{2/n} \right) \\
        & = P\left(\bar{X} - \bar{Y} >  z(\alpha/2) \sigma \sqrt{2/n} \right) + P\left( \bar{X} - \bar{Y} <  -z(\alpha/2) \sigma \sqrt{2/n} \right) \\
        & = P\left(\frac{(\bar{X} - \bar{Y})-\triangle}{\sigma \sqrt{2/n}} >  \frac{z(\alpha/2) \sigma \sqrt{2/n}-\triangle}{\sigma\sqrt{2/n}} \right) + P\left( \bar{X} - \bar{Y} <  -z(\alpha/2) \sigma \sqrt{2/n} \right)\\
        & = 1 - \Phi\left( z(\alpha/2) - \frac{\triangle}{\sigma}\sqrt{n/2}\right) +  P\left( \bar{X} - \bar{Y} <  -z(\alpha/2) \sigma \sqrt{2/n} \right)\\
        & =  1 - \Phi\left( z(\alpha/2) - \frac{\triangle}{\sigma}\sqrt{n/2}\right) + \Phi\left( -z(\alpha/2) - \frac{\triangle}{\sigma}\sqrt{n/2}\right)
    \end{align*}